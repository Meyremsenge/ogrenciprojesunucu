# ğŸ›¡ï¸ AI Anti-Pattern ve Risk Listesi

Bu dokÃ¼man, AI DanÄ±ÅŸman modÃ¼lÃ¼ndeki potansiyel gÃ¼venlik risklerini, anti-pattern'leri ve bunlarÄ±n Ã¶nleme yÃ¶ntemlerini detaylÄ± ÅŸekilde aÃ§Ä±klar.

---

## ğŸ“‹ Ä°Ã§indekiler

1. [GÃ¼venlik Riskleri](#-gÃ¼venlik-riskleri)
2. [Performans & Maliyet Riskleri](#-performans--maliyet-riskleri)
3. [Pedagojik & ÃœrÃ¼n Riskleri](#-pedagojik--Ã¼rÃ¼n-riskleri)
4. [Uygulanan Ã–nlemler](#-uygulanan-Ã¶nlemler)
5. [Kontrol Listesi](#-kontrol-listesi)

---

## ğŸ” GÃ¼venlik Riskleri

### 1. AI Chat PromptlarÄ±nÄ±n Frontend'de Hardcode Edilmesi

#### âŒ Neden Tehlikeli?
- Prompt'lar client-side JavaScript'te gÃ¶rÃ¼nÃ¼r
- Prompt injection saldÄ±rÄ±larÄ± kolaylaÅŸÄ±r
- Sistem davranÄ±ÅŸÄ± manipÃ¼le edilebilir
- Rakipler prompt engineering stratejinizi kopyalayabilir

#### ğŸ” NasÄ±l Tespit Edilir?
```bash
# Frontend kodunda prompt aramasÄ±
grep -r "system.*prompt\|role.*system\|You are" frontend/src/
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend:**
- TÃ¼m prompt'lar `app/modules/ai/prompts/templates/` klasÃ¶rÃ¼nde YAML olarak saklanÄ±r
- `PromptManager` class'Ä± template'leri yÃ¼kler ve render eder
- Frontend'e sadece feature adÄ± gÃ¶nderilir

**Frontend:**
```typescript
// âŒ YANLIÅ - Prompt frontend'de
const response = await api.post('/ai/chat', {
  messages: [
    { role: 'system', content: 'Sen bir eÄŸitim asistanÄ±sÄ±n...' },
    { role: 'user', content: userMessage }
  ]
});

// âœ… DOÄRU - Sadece feature adÄ±
const response = await api.post('/ai/hint', {
  question_text: userMessage,
  difficulty_level: 'medium'
});
```

**Dosyalar:**
- `app/modules/ai/prompts/manager.py` - Template yÃ¶netimi
- `app/modules/ai/prompts/templates/*.yaml` - Prompt dosyalarÄ±

---

### 2. AI API AnahtarÄ±nÄ±n Backend DÄ±ÅŸÄ±na SÄ±zmasÄ±

#### âŒ Neden Tehlikeli?
- KÃ¶tÃ¼ niyetli kullanÄ±cÄ±lar anahtarÄ± kullanabilir
- Maliyet kontrolÃ¼ kaybedilir
- API kullanÄ±m limitleri aÅŸÄ±labilir
- Yasal sorumluluk doÄŸar

#### ğŸ” NasÄ±l Tespit Edilir?
```bash
# Git history'de API key aramasÄ±
git log -p | grep -i "sk-\|api_key\|apikey"

# Environment variable kontrolÃ¼
grep -r "OPENAI\|API_KEY" --include="*.ts" --include="*.tsx" frontend/

# Log dosyalarÄ±nda API key kontrolÃ¼
grep -r "sk-" logs/
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend:**
```python
# app/modules/ai/config.py - GÃ¼venli API key yÃ¶netimi
class AIConfig:
    def get_masked_api_key(self) -> str:
        """Log iÃ§in maskelenmiÅŸ key dÃ¶ner."""
        if not self._api_key:
            return "[NOT_SET]"
        return f"{self._api_key[:7]}...{self._api_key[-4:]}"
    
    def validate_api_key(self, key: str) -> bool:
        """API key formatÄ±nÄ± doÄŸrula."""
        if not key:
            return False
        return key.startswith(('sk-', 'sk-proj-'))
```

**Environment:**
```bash
# .env dosyasÄ± (git'e eklenmemeli)
OPENAI_API_KEY=sk-proj-xxx...

# .gitignore
.env
.env.local
*.env
```

**Log Sanitization:**
```python
# app/modules/ai/security/sanitizer.py
class OutputSanitizer:
    SECRET_PATTERNS = [
        r'sk-[a-zA-Z0-9]{20,}',  # OpenAI keys
        r'api[_-]?key["\s:=]+[a-zA-Z0-9]{20,}',
    ]
```

---

### 3. Ã–ÄŸrenci Verilerinin Prompt Ä°Ã§ine KontrolsÃ¼z Eklenmesi

#### âŒ Neden Tehlikeli?
- KVKK/GDPR ihlali
- Ã–ÄŸrenci mahremiyeti tehlikeye girer
- AI provider'a kiÅŸisel veri sÄ±zar
- Yasal yaptÄ±rÄ±mlar

#### ğŸ” NasÄ±l Tespit Edilir?
```python
# Prompt iÃ§eriÄŸinde PII kontrolÃ¼
grep -r "student_name\|email\|tc_kimlik\|phone" app/modules/ai/
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - PII Detection & Masking:**
```python
# app/modules/ai/security/detector.py
class PIIDetector:
    """KiÅŸisel veri tespit sistemi."""
    
    PATTERNS = {
        "tc_kimlik": r"\b[1-9][0-9]{10}\b",
        "email": r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}",
        "phone": r"\b(05\d{9}|\+90\s*5\d{2}\s*\d{3}\s*\d{2}\s*\d{2})\b",
        "credit_card": r"\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b",
    }
    
    def detect_and_mask(self, content: str) -> str:
        """PII tespit et ve maskele."""
        for pii_type, pattern in self.PATTERNS.items():
            content = re.sub(pattern, f"[{pii_type.upper()}_MASKED]", content)
        return content
```

**Prompt Template'lerinde GÃ¼venli DeÄŸiÅŸkenler:**
```yaml
# templates/question_hint.yaml
required_variables:
  - question_text    # âœ… GÃ¼venli - soru iÃ§eriÄŸi
  - difficulty_level # âœ… GÃ¼venli - zorluk seviyesi

# âŒ YASAK deÄŸiÅŸkenler (template'de kullanÄ±lamaz)
forbidden_variables:
  - student_name
  - student_email
  - tc_kimlik
  - phone_number
```

---

### 4. AI Ã‡Ä±ktÄ±larÄ±nÄ±n Loglarda KiÅŸisel Veri Ä°Ã§ermesi

#### âŒ Neden Tehlikeli?
- Log dosyalarÄ± sÄ±zarsa KVKK ihlali
- Compliance denetimleri baÅŸarÄ±sÄ±z olur
- Forensics zorlaÅŸÄ±r (aÅŸÄ±rÄ± veri)

#### ğŸ” NasÄ±l Tespit Edilir?
```bash
# Log dosyalarÄ±nda PII aramasÄ±
grep -E "[1-9][0-9]{10}|[a-zA-Z0-9._%+-]+@|05[0-9]{9}" logs/*.log
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - Output Log Sanitization:**
```python
# app/modules/ai/security/audit.py
class SecurityAuditLogger:
    def _sanitize_for_log(self, content: str) -> str:
        """Log iÃ§in iÃ§eriÄŸi temizle."""
        # PII maskele
        content = self.pii_detector.mask(content)
        # Ä°lk 100 karakteri al
        if len(content) > 100:
            content = content[:100] + "...[TRUNCATED]"
        return content
    
    def log_ai_response(self, response: str, user_id: int):
        """AI yanÄ±tÄ±nÄ± gÃ¼venli ÅŸekilde logla."""
        self.log(SecurityEvent(
            event_type=SecurityEventType.AI_RESPONSE,
            content_hash=hashlib.sha256(response.encode()).hexdigest()[:16],
            content_preview=self._sanitize_for_log(response),
            user_id=user_id
        ))
```

**Log Retention Policy:**
```python
# 90 gÃ¼n sonra otomatik temizlik
RETENTION_DAYS = 90
```

---

## âš™ï¸ Performans & Maliyet Riskleri

### 5. Her Mesajda Context'in SÄ±nÄ±rsÄ±z BÃ¼yÃ¼mesi

#### âŒ Neden Tehlikeli?
- Token maliyeti katlanarak artar
- API rate limitleri aÅŸÄ±lÄ±r
- YanÄ±t sÃ¼resi uzar
- Memory overflow riski

#### ğŸ” NasÄ±l Tespit Edilir?
```python
# Context boyutu metriÄŸi
avg_context_tokens = sum(request.context_tokens for request in requests) / len(requests)
if avg_context_tokens > 2000:
    alert("Context boyutu Ã§ok bÃ¼yÃ¼k!")
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - Context Limiter Middleware:**
```python
# app/modules/ai/middleware/context_limiter.py
class ContextLimiter:
    MAX_CONTEXT_TOKENS = 2000
    MAX_CONVERSATION_HISTORY = 10
    
    def limit_context(self, messages: List[dict]) -> List[dict]:
        """Context'i sÄ±nÄ±rla."""
        # Son N mesajÄ± al
        messages = messages[-self.MAX_CONVERSATION_HISTORY:]
        
        # Token sayÄ±sÄ±nÄ± kontrol et
        total_tokens = sum(self._count_tokens(m) for m in messages)
        while total_tokens > self.MAX_CONTEXT_TOKENS and len(messages) > 2:
            messages.pop(0)  # En eski mesajÄ± kaldÄ±r
            total_tokens = sum(self._count_tokens(m) for m in messages)
        
        return messages
```

**Frontend - Conversation Pruning:**
```typescript
// stores/aiChatStore.ts
const MAX_MESSAGES = 10;

function addMessage(message: ChatMessage) {
  messages.push(message);
  // Eski mesajlarÄ± temizle
  if (messages.length > MAX_MESSAGES) {
    messages = messages.slice(-MAX_MESSAGES);
  }
}
```

---

### 6. Streaming Response YÃ¶netilmemesi

#### âŒ Neden Tehlikeli?
- KullanÄ±cÄ± uzun sÃ¼re bekler (UX kÃ¶tÃ¼)
- Timeout hatalarÄ±
- Connection kaynaklarÄ± tÃ¼kenir

#### ğŸ” NasÄ±l Tespit Edilir?
```python
# Ortalama yanÄ±t sÃ¼resi > 10 saniye ise sorun var
if avg_response_time > 10:
    alert("Streaming implemente edilmeli!")
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - SSE Streaming:**
```python
# app/modules/ai/routes_v3.py
@ai_bp.route('/stream/hint', methods=['POST'])
@jwt_required()
def stream_hint():
    """Server-Sent Events ile streaming."""
    def generate():
        for chunk in ai_service.stream_hint(data):
            yield f"data: {json.dumps(chunk)}\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )
```

**Frontend - EventSource:**
```typescript
// services/aiStreamService.ts
function streamHint(question: string, onChunk: (text: string) => void) {
  const eventSource = new EventSource(`/api/v1/ai/stream/hint?q=${encodeURIComponent(question)}`);
  
  eventSource.onmessage = (event) => {
    const data = JSON.parse(event.data);
    onChunk(data.text);
  };
  
  eventSource.onerror = () => eventSource.close();
}
```

---

### 7. AI Rate Limit OlmamasÄ±

#### âŒ Neden Tehlikeli?
- Tek kullanÄ±cÄ± tÃ¼m kaynaklarÄ± tÃ¼ketebilir
- DoS saldÄ±rÄ±larÄ±na aÃ§Ä±k
- Maliyet kontrolÃ¼ imkansÄ±z

#### ğŸ” NasÄ±l Tespit Edilir?
```python
# Dakikada 100+ istek yapan kullanÄ±cÄ±lar
high_frequency_users = get_users_with_rpm_over(100)
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - Multi-Layer Rate Limiting:**
```python
# app/modules/ai/quota/rate_limiter.py
class AIRateLimiter:
    """Ã‡ok katmanlÄ± rate limiting."""
    
    LIMITS = {
        'global': {'rpm': 60, 'tpm': 100000, 'rpd': 10000},
        'per_user': {
            'student': {'rpm': 10, 'tpm': 10000, 'rpd': 100},
            'teacher': {'rpm': 30, 'tpm': 30000, 'rpd': 500},
        }
    }
    
    def check_limits(self, user_id: int, role: str, tokens: int) -> bool:
        # Global limit
        if self.get_global_rpm() >= self.LIMITS['global']['rpm']:
            raise AIRateLimitError("Sistem meÅŸgul, lÃ¼tfen bekleyin")
        
        # User limit
        user_limits = self.LIMITS['per_user'].get(role, self.LIMITS['per_user']['student'])
        if self.get_user_rpm(user_id) >= user_limits['rpm']:
            raise AIRateLimitError("Rate limit aÅŸÄ±ldÄ±")
```

---

### 8. KullanÄ±cÄ± BaÅŸÄ±na AI Limitinin OlmamasÄ±

#### âŒ Neden Tehlikeli?
- Ã–ÄŸrenciler sistemi sÄ±nÄ±rsÄ±z kullanabilir
- Maliyet tahmin edilemez
- Adil kullanÄ±m saÄŸlanamaz

#### ğŸ” NasÄ±l Tespit Edilir?
```sql
SELECT user_id, COUNT(*) as request_count, SUM(tokens) as total_tokens
FROM ai_requests 
WHERE created_at > NOW() - INTERVAL '1 day'
GROUP BY user_id
ORDER BY total_tokens DESC;
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - Rol BazlÄ± Kota Sistemi:**
```python
# app/modules/ai/core/constants.py
QUOTA_LIMITS = {
    'student': {
        'daily_tokens': 1000,
        'monthly_tokens': 20000,
        'daily_requests': 20,
        'max_tokens_per_request': 200,
        'cooldown_seconds': 30,
    },
    'teacher': {
        'daily_tokens': 5000,
        'monthly_tokens': 100000,
        'daily_requests': 100,
        'max_tokens_per_request': 500,
        'cooldown_seconds': 10,
    },
    'admin': {
        'daily_tokens': 20000,
        'monthly_tokens': 500000,
        'daily_requests': 500,
        'max_tokens_per_request': 1000,
        'cooldown_seconds': 5,
    },
    'super_admin': {
        'daily_tokens': -1,  # SÄ±nÄ±rsÄ±z
        'monthly_tokens': -1,
        'daily_requests': -1,
        'max_tokens_per_request': -1,
        'cooldown_seconds': 0,
    }
}
```

---

## ğŸ§  Pedagojik & ÃœrÃ¼n Riskleri

### 9. AI'nin Ã–ÄŸretmen Yerine KonumlandÄ±rÄ±lmasÄ±

#### âŒ Neden Tehlikeli?
- Ã–ÄŸrenciler Ã¶ÄŸretmene gÃ¼venini kaybeder
- Ã–ÄŸrenme sÃ¼reci zarar gÃ¶rÃ¼r
- YanlÄ±ÅŸ bilgi dÃ¼zeltilmez

#### ğŸ” NasÄ±l Tespit Edilir?
```python
# AI kullanÄ±m oranÄ± vs Ã¶ÄŸretmen etkileÅŸimi
ai_usage_ratio = ai_requests / teacher_interactions
if ai_usage_ratio > 5:
    alert("AI aÅŸÄ±rÄ± kullanÄ±lÄ±yor!")
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - AI Role Limitation:**
```yaml
# prompts/templates/question_hint.yaml
system_prompt: |
  Sen bir eÄŸitim YARDIMCISISIN, Ã¶ÄŸretmen DEÄÄ°LSÄ°N.
  
  KRÄ°TÄ°K KURALLAR:
  1. Asla cevabÄ± doÄŸrudan verme
  2. Sadece yÃ¶nlendirici ipuÃ§larÄ± ver
  3. Ã–ÄŸrenciyi dÃ¼ÅŸÃ¼nmeye teÅŸvik et
  4. "Ã–ÄŸretmeninize danÄ±ÅŸÄ±n" Ã¶nerisinde bulun
  5. KarmaÅŸÄ±k konularda Ã¶ÄŸretmene yÃ¶nlendir
```

**Frontend - Disclaimer Banner:**
```typescript
// components/ai/AIDisclaimer.tsx
export const AIDisclaimer = () => (
  <Alert variant="info">
    <AlertIcon />
    <AlertDescription>
      AI asistan sadece yardÄ±mcÄ± bir araÃ§tÄ±r. 
      Kesin bilgi iÃ§in Ã¶ÄŸretmeninize danÄ±ÅŸÄ±n.
    </AlertDescription>
  </Alert>
);
```

---

### 10. YanlÄ±ÅŸ Bilgi Ãœretiminin KontrolsÃ¼z SunulmasÄ±

#### âŒ Neden Tehlikeli?
- Ã–ÄŸrenciler yanlÄ±ÅŸ Ã¶ÄŸrenir
- GÃ¼ven kaybÄ± yaÅŸanÄ±r
- EÄŸitim kalitesi dÃ¼ÅŸer

#### ğŸ” NasÄ±l Tespit Edilir?
```python
# Ã–ÄŸretmen dÃ¼zeltme oranÄ±
correction_rate = teacher_corrections / ai_responses
if correction_rate > 0.1:  # %10'dan fazla dÃ¼zeltme
    alert("AI yanÄ±t kalitesi dÃ¼ÅŸÃ¼k!")
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - Confidence Score & Disclaimer:**
```python
# app/modules/ai/services/hint_service.py
class HintService:
    def generate_hint(self, question: str) -> AIResponse:
        response = self.provider.generate(prompt)
        
        # Confidence dÃ¼ÅŸÃ¼kse disclaimer ekle
        if response.confidence < 0.7:
            response.disclaimer = "Bu bilgi kesin olmayabilir. LÃ¼tfen Ã¶ÄŸretmeninize danÄ±ÅŸÄ±n."
        
        return response
```

**AI Output Wrapper:**
```python
# app/modules/ai/core/response_wrapper.py
@dataclass
class AIResponseWrapper:
    content: str
    confidence: float
    disclaimer: Optional[str] = None
    source_references: List[str] = field(default_factory=list)
    needs_verification: bool = False
    
    def to_safe_response(self) -> dict:
        return {
            "content": self.content,
            "disclaimer": self.disclaimer or "Bu AI tarafÄ±ndan Ã¼retilmiÅŸ bir iÃ§eriktir.",
            "needs_verification": self.confidence < 0.8,
            "ai_generated": True
        }
```

---

### 11. AI'nin SÄ±nav veya DeÄŸerlendirme SÃ¼reÃ§lerine SÄ±zmasÄ±

#### âŒ Neden Tehlikeli?
- Akademik dÃ¼rÃ¼stlÃ¼k ihlali
- DeÄŸerlendirme geÃ§ersiz olur
- Ã–ÄŸrenciler arasÄ± adaletsizlik

#### ğŸ” NasÄ±l Tespit Edilir?
```sql
-- SÄ±nav sÄ±rasÄ±nda AI kullanÄ±mÄ±
SELECT u.id, e.title, COUNT(ar.id) as ai_requests
FROM users u
JOIN exam_attempts ea ON u.id = ea.user_id
JOIN ai_requests ar ON u.id = ar.user_id
WHERE ar.created_at BETWEEN ea.started_at AND ea.completed_at
GROUP BY u.id, e.title;
```

#### âœ… Ã–nleme YÃ¶ntemleri

**Backend - Exam Context Blocker:**
```python
# app/modules/ai/security/exam_guard.py
class ExamContextGuard:
    """SÄ±nav sÃ¼recinde AI eriÅŸimini engeller."""
    
    def check_exam_context(self, user_id: int) -> bool:
        """KullanÄ±cÄ± aktif sÄ±navda mÄ± kontrol et."""
        active_exam = ExamAttempt.query.filter(
            ExamAttempt.user_id == user_id,
            ExamAttempt.status == 'in_progress'
        ).first()
        
        if active_exam:
            raise AIAccessDeniedError(
                "SÄ±nav sÃ¼resince AI asistan kullanÄ±lamaz.",
                error_code="EXAM_IN_PROGRESS"
            )
        return True
```

**Route-Level Protection:**
```python
# app/modules/ai/routes.py
@ai_bp.before_request
def check_exam_context():
    """Her AI isteÄŸinden Ã¶nce sÄ±nav kontrolÃ¼."""
    user_id = get_jwt_identity()
    if user_id:
        exam_guard.check_exam_context(user_id)
```

**Frontend - Exam Mode Detection:**
```typescript
// hooks/useAIChat.ts
function useAIChat() {
  const { isInExam } = useExamContext();
  
  const sendMessage = async (message: string) => {
    if (isInExam) {
      toast.error("SÄ±nav sÃ¼resince AI asistan kullanÄ±lamaz.");
      return;
    }
    // ... normal flow
  };
}
```

---

## âœ… Uygulanan Ã–nlemler

### Backend GÃ¼venlik KatmanlarÄ±

| Katman | Dosya | AÃ§Ä±klama |
|--------|-------|----------|
| Prompt Manager | `ai/prompts/manager.py` | Template tabanlÄ± prompt yÃ¶netimi |
| PII Detector | `ai/security/detector.py` | KiÅŸisel veri tespiti |
| Input Sanitizer | `ai/security/sanitizer.py` | Girdi temizleme |
| Output Sanitizer | `ai/security/sanitizer.py` | Ã‡Ä±ktÄ± temizleme |
| Injection Detector | `ai/security/detector.py` | Prompt injection tespiti |
| Jailbreak Detector | `ai/security/detector.py` | Jailbreak tespiti |
| Security Guard | `ai/security/guard.py` | Merkezi gÃ¼venlik kontrolÃ¼ |
| Rate Limiter | `ai/quota/rate_limiter.py` | Ä°stek sÄ±nÄ±rlama |
| Quota Manager | `ai/quota/quota_manager.py` | Kota yÃ¶netimi |
| Abuse Detector | `ai/quota/abuse_detector.py` | KÃ¶tÃ¼ye kullanÄ±m tespiti |
| Audit Logger | `ai/security/audit.py` | GÃ¼venlik loglama |

### API Key GÃ¼venliÄŸi

- âœ… Environment variable'da saklanÄ±r
- âœ… `.gitignore`'da yer alÄ±r
- âœ… Log'larda maskelenir
- âœ… Format validation yapÄ±lÄ±r
- âœ… Frontend'e hiÃ§ gÃ¶nderilmez

### Rol BazlÄ± EriÅŸim

| Ã–zellik | Student | Teacher | Admin |
|---------|:-------:|:-------:|:-----:|
| question_hint | âœ… | âœ… | âœ… |
| topic_explanation | âœ… | âœ… | âœ… |
| study_plan | âœ… | âœ… | âœ… |
| question_generation | âŒ | âœ… | âœ… |
| answer_evaluation | âŒ | âœ… | âœ… |

---

## ğŸ“ Kontrol Listesi

### Deployment Ã–ncesi

- [ ] API key'ler environment variable'da mÄ±?
- [ ] `.env` dosyasÄ± `.gitignore`'da mÄ±?
- [ ] Log dosyalarÄ±nda PII var mÄ±?
- [ ] Rate limit ayarlarÄ± uygun mu?
- [ ] Kota limitleri tanÄ±mlÄ± mÄ±?
- [ ] SÄ±nav modu korumasÄ± aktif mi?
- [ ] Disclaimer metinleri yerinde mi?
- [ ] Context limit ayarlarÄ± yapÄ±ldÄ± mÄ±?

### HaftalÄ±k Kontrol

- [ ] Kota aÅŸÄ±m raporlarÄ± incelendi mi?
- [ ] Rate limit hit oranlarÄ± normal mi?
- [ ] Security alert'ler gÃ¶zden geÃ§irildi mi?
- [ ] Maliyet analizi yapÄ±ldÄ± mÄ±?
- [ ] Ã–ÄŸretmen geri bildirimleri deÄŸerlendirildi mi?

### AylÄ±k Audit

- [ ] PII log taramasÄ± yapÄ±ldÄ± mÄ±?
- [ ] API key rotation gerekli mi?
- [ ] Prompt template'ler gÃ¼ncellendi mi?
- [ ] Kota limitleri gÃ¶zden geÃ§irildi mi?
- [ ] Abuse pattern analizi yapÄ±ldÄ± mÄ±?

---

## ğŸ“š Ä°lgili Dosyalar

```
app/modules/ai/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ constants.py      # Sabitler ve limitler
â”‚   â”œâ”€â”€ exceptions.py     # Hata sÄ±nÄ±flarÄ±
â”‚   â””â”€â”€ interfaces.py     # ArayÃ¼zler
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ manager.py        # Template yÃ¶netimi
â”‚   â””â”€â”€ templates/        # YAML prompt'larÄ±
â”œâ”€â”€ quota/
â”‚   â”œâ”€â”€ quota_manager.py  # Kota yÃ¶netimi
â”‚   â”œâ”€â”€ rate_limiter.py   # Rate limiting
â”‚   â””â”€â”€ abuse_detector.py # Abuse tespiti
â”œâ”€â”€ security/
â”‚   â”œâ”€â”€ guard.py          # Merkezi gÃ¼venlik
â”‚   â”œâ”€â”€ detector.py       # Tehdit tespiti
â”‚   â”œâ”€â”€ sanitizer.py      # Temizleme
â”‚   â””â”€â”€ audit.py          # Loglama
â””â”€â”€ middleware/
    â”œâ”€â”€ context_limiter.py  # Context sÄ±nÄ±rlama
    â””â”€â”€ exam_guard.py       # SÄ±nav korumasÄ±
```
